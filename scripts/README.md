# Overview

This directory contains a set of data curation helper scripts. It assumes the use of the iReceptor Data Loading module python software, and is designed to work from within the iReceptor Turnkey Repository platform (https://github.com/sfu-ireceptor). There are three bash helper scripts, one that is designed to load all of the data for a single AIRR-seq study, one that is designed to load just the repertoire metadata for a study, and one that is designed to load a set of rearrangement files for a set of repertoires from a study (assuming that the repertoire metadata is already loaded). These tools are described in more detail below.

## Study data loading

The iReceptor team uses a standard data curation process, as documented here: http://www.ireceptor.org/curation. This curation process assumes that the immune repertoires that are associated with a particular study are described in a single repertoire metadata file. The repertoire metadata file is a UTF-8 encoded comman delimeted file (a CSV file), consisting of a header line (which denotes the repertoire metadata field names) and a single line for each repertioire that describes the metadata fields for that repertiore. 

For each repertoire, there are typically one more rearrangement files that are associated with that repertoire, and  each rearrangement file is generated by one of the widely used annotation tools (currently MiXCR, IMGT HighV-QUEST, and igblast are supported). It is assumed that all rearrangement files for a study are generated by the same annotation tool.

The study loading helper script can be used to load an entire study with one command. Data provenance is supported by ensuring that the output generated each time a data set is loaded is logged in an output file. It should be noted that depending on the size of the study, the data loading could take a very long time.

One uses the helper script by providing the following information:

1. The repertoire metadata file for the study.
2. The output directory where the log files for the data loading will be written.
3. The type of annotation tool that was used to generate the rearrangment files.
4. A set of rearrangement files to process.

For example, the IMGT HighV-QUEST test data set that is in the test directory "test/imgt/imgt" consists of a repertoire metadata file (PRJNA248411_Palanichamy_2018-12-18.csv) and a set of eight annotated rearrangement files (SRR1298733.txz, SRR1298738.txz, SRR1298731.txz. SRR1298734.txz, SRR1298740.txz, SRR1298732.txz, SRR1298736.txz, SRR1298742.txz). In order to load this data set, assuming you were issuing the command from the "test/imgt/imgt" directory, one could use the following command:

load_study.sh PRJNA248411_Palanichamy_2018-12-18.csv . imgt \*.txz

This command would first load the repertoire metadata file and the load all of the .txz files. The "imgt" command line arguement tells the data loader that the files are in the IMGT HighV-QUEST format and "." command line parameter tells the script to generate log files in the current directory.

Note because the data loading process can take a very long time (many hours for large studies) it is a good idea to run this command in the background using the Unix "nohup" command. This will ensure that the command will run in the background and will not be interupted when the user logs out of the system being used to load the data. A typical usage in this scenario would be:

nohup load_study.sh PRJNA248411_Palanichamy_2018-12-18.csv . imgt \*.txz > nohup.out &
